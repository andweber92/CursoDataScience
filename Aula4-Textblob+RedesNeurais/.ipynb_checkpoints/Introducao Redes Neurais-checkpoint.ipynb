{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdução a redes neurais\n",
    "\n",
    "\n",
    "## Introdução \n",
    "\n",
    "O estudo de redes neurais (neurocomputação) surgiram em 1943, com Warren McCulloch e Walter Pitts, mas o que são redes neurais artificiais - RNA’s basicamente modelos matemáticos inspirados no princípio de funcionamento do neurônio biológico, elas buscam simular habilidades humanas tais como: aprendizado, generalização, associação e abstração.\n",
    "\n",
    "\n",
    "## Características de uma Rede Neural\n",
    "\n",
    "Algumas características de uma RNA.\n",
    "\n",
    "+ Busca paralela .\n",
    "A procura pela informação ocorre de maneira paralela e não sequencial.\n",
    "\n",
    "+ Generalização muito boa.\n",
    "Essa é uma das que considero muito boa, pois, é a partir de exemplos anteriores uma RNA é capaz de generalizar seu conhecimento exemplo: enviamos para nossa rede treinar com diversas formas de escrita da letra “A” logo com isso quando escrevermos algo próximo a letra “A” nossa rede ira identificar muito bom né, serve para o alfabeto todo.\n",
    "\n",
    "Aprendem padrões a partir dos dados que são abstraídos de modelos de conhecimento. O aprendizado é realizado/implementado por um algoritmo de aprendizado.\n",
    "\n",
    "Abstração muito boa .\n",
    "Capacidade de identificar a essência a partir de um conjunto de dados de entrada. A partir de padrões ruidosos uma RNA pode extrair as informações do padrão se ruído.\n",
    "\n",
    "+ São não programáveis.\n",
    "Uma RNA deve ser modelada segundo as entradas e saídas envolvidas em um algoritmo de aprendizado, buscando mapear corretamente as entradas nas saídas correspondentes\n",
    "\n",
    "+ Soluções aproximadas .\n",
    "Muitas vezes uma RNA produz uma solução aproximada para um determinado problema. As RNA´s são suscetíveis a geração de soluções incorretas.\n",
    "\n",
    "## Redes Neurais Artificiais RNA\n",
    "\n",
    "RNA’s que são formada por neurônios artificiais com conexões ponderadas por valores denominados pesos, em uma RNA seus neurônios são arrumados em camadas com conexões entre elas que são organizadas em: camada de entrada, camada de saída e camada intermediária, comumente chamada de camada oculta.\n",
    "\n",
    "![IMG1](http://www.matheusfrancisco.com.br/images/introducao-a-redes-neurais/mlp.JPG)\n",
    "\n",
    "No caso da nossa imagem meramente ilustrativa de uma rede neural do tipo MLP (multilayer perceptron) temos as camadas de entrada, oculta (intermediária) e saídas.\n",
    "\n",
    "Os neurônio artificial é projetado para imitar algumas das principais características de um biológico as entradas de neuro artificial é multiplicada por um peso Qij, gerando entradas ponderadas, todas as entradas ponderadas são somadas obtendo-se um valor NET que é o potencial de ativação do neurônio artificial. Com isso o valor do NET será comparado ao valor limite para ativação do neurônio\n",
    "\n",
    "![IMG2](http://www.matheusfrancisco.com.br/images/introducao-a-redes-neurais/wij.png)\n",
    "\n",
    "## Conexões entre neurônios.\n",
    "Como cada neurônio artificial possui seu valor real chamado peso sináptico, dependendo do valor do peso maior ou menor será influência positiva ou negativa do neurônio\n",
    "\n",
    "![IMG3](http://www.matheusfrancisco.com.br/images/introducao-a-redes-neurais/conexao.png)\n",
    "\n",
    "## Regra de propagação.\n",
    "Quando os estímulos provenientes de outros neurônios são combinados aos pesos sinápticos correspondentes para compor o potencial de ativação, então a regra de propagação estabelece o potencial de ativação de um neurônio NET(k), cujo a regra pode ser um produto escalar entre o vetor de entrada e o vetor de pesos.\n",
    "\n",
    "![IMG4](http://www.matheusfrancisco.com.br/images/introducao-a-redes-neurais/regra.png)\n",
    "\n",
    "## Funções de ativação.\n",
    "Esta é a função que determina o novo valor do estado de ativação do neurônio a partir do potencial de ativação Net(k), assim determina a saída efetiva de um neurônio artificial Sk= F(Netk + bk) onde F é a função de ativação do neurônio e bk é uma constantes que tem efeito de aumentar ou diminuir a entrada líquida da função de ativação, comumente chamada de bias.\n",
    "\n",
    "![IMG4](https://cdn-images-1.medium.com/max/1200/1*ZafDv3VUm60Eh10OeJu1vw.png)\n",
    "[Fonte](https://cdn-images-1.medium.com/max/1200/1*ZafDv3VUm60Eh10OeJu1vw.png)\n",
    "\n",
    "## Arquiteturas de RNA´s\n",
    "Exitem redes com apenas uma camada de neurônios, múltiplas camadas, redes feedforward( acíclica), redes feddback ( cíclica), redes com recorrência auto-associativa, porém não irei explicar todas aqui tentarei fazer postagem de desenvolvimento com redes neurais de múltiplas camadas e poucas camadas.\n",
    "\n",
    "## Processamento neural\n",
    "Os processamentos neural artificial pode ser dividio em aprendizado onde é um processo de atualização dos pesos sinápticos para aquisição do conhecimento, s os pesos são atualizados conforme o algoritmo de aprendizado escolhido e o vetor de pesos w(t+1) no instante t+1 pode ser escrito com \n",
    "\n",
    "$$w(t+1) = w(t) +lw(t)$$ \n",
    "\n",
    "onde lw(t) é o ajuste aplicado aos pesos, podemos falar que os algoritmos de aprendizado diferem na forma de como é calculado lw(t).\n",
    "\n",
    "O processo de aprendizado possui os seguintes passos: \n",
    "\n",
    "+ A rede neural é estimulada ao receber um padrão de entrada retirado de um conjunto histórico de padrões ou dados.\n",
    "+ A rede neural sofre modificações em seus parâmetros livres.\n",
    "+ A rede neural responde de uma nova maneira ao ambiente.\n",
    "Estes passos são repetidos até um critério de parada seja estabelecido, podendo ser: número de iterações máximo atingido ou erro produzido pela rede atinge um patmar abaixo do limiar definido, devemos levar em consideração que uma rede só pode ser aplicada a um problema após ter sido treinada, na fase de aplicação não há atualizações dos pesos sinápticos\n",
    "\n",
    "## Tipos de aprendizados em rna\n",
    "Temos aprendizado supervisionado, onde os pesos sinápticos são atualizados até que o valor do erro fique abaixo de um limite máximo de tolerância especificado pelo usuário.\n",
    "\n",
    "![IMG5](http://www.matheusfrancisco.com.br/images/introducao-a-redes-neurais/super.png)\n",
    "\n",
    "Este tipo de aprendizado envolve a minimização da soma dos erros quadráticos das saídas.\n",
    "\n",
    "![IMG6](http://www.matheusfrancisco.com.br/images/introducao-a-redes-neurais/nsuper.png)\n",
    "\n",
    "Também temos os não supervisionado trabalha os dados de maneira a determinar algumas propriedades dos conjuntos de dados não existe para cada entrada uma saída desejada, regularidade e redundância nas entradas são características essenciais para haver aprendizado não supervisionado. Esse tipo de aprendizado é muito útil para agrupamento de dados e temos o aprendizado por reforço que é útil para aplicação de tarefas de controle, porém não irei falar muito que a postagem já ficou muito chatinha.\n",
    "\n",
    "## Conclusão\n",
    "Redes neurais que podem ser utilizadas para os seguintes problemas: classificação de padrões, reconhecimento de padrões, correção de padrões, previsão de séries temporais, mineração de dados e suporte à decisão."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fontes:\n",
    "[Blog Do Xicao](http://www.matheusfrancisco.com.br/introdu%C3%A7%C3%A3o-a-rede-neural/)\n",
    "\n",
    "Um Introdução a Inteligência Computacional: fundamentos, ferramentas e aplicações. GOLDSCHIMIDT, R. L. Rio de Janeiro, 2010. Editora IST-RJ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementação deep Learning \n",
    "\n",
    "A aprendizagem profunda, do inglês Deep Learning (também conhecida como aprendizado estruturado profundo, aprendizado hierárquico ou aprendizado de máquina profundo) é um ramo de aprendizado de máquina (Machine Learning) baseado em um conjunto de algoritmos que tentam modelar abstrações de alto nível de dados usando um grafo profundo com várias camadas de processamento, compostas de várias transformações lineares e não lineares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-4-be7a242f821a>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-4-be7a242f821a>\"\u001b[1;36m, line \u001b[1;32m6\u001b[0m\n\u001b[1;33m    \u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class mlp:\n",
    "    def __init__(self, entradas=2, saidas=2, amostras=11, neuronios=6, camadas=2, epocas=10000, txAprendizado=0.9):\n",
    "        self.entradas = entradas\n",
    "        self.saidas = saidas\n",
    "        self.amostras = amostras\n",
    "        self.neuronio = neuronio\n",
    "        self.camadas = camadas\n",
    "        self.epocas = epocas\n",
    "        self.txAprendizado = txAprendizado\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
